import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import time
import random

def refresh_session():
    new_session = requests.Session()
    new_session.headers.update(headers)
    return new_session

# ê¸°ë³¸ ì„¤ì •
base_url = "https://www.fmkorea.com/index.php?mid=hotdeal&page={}"
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/117.0.0.0 Safari/537.36",
    "Referer": "https://www.fmkorea.com/",
    "Accept-Language": "ko-KR,ko;q=0.9"

}
max_days = 7
now = datetime.now()
page = 1
stop = False

# ì„¸ì…˜ ìœ ì§€
session = requests.Session()
session.headers.update(headers)

while not stop:
    print(f"ğŸ“„ í˜ì´ì§€ {page} í¬ë¡¤ë§ ì¤‘...")
    try:
        response = session.get(base_url.format(page))
        soup = BeautifulSoup(response.text, "html.parser")

        items = soup.select("li.li_best2_hotdeal0")
        if not items:
            print("âŒ ì¿ í‚¤ ë§Œë£Œ ë˜ëŠ” ì„œë²„ ì‘ë‹µ ì´ìƒ. ì„¸ì…˜ ê°±ì‹  ì‹œë„ ì¤‘...")
            session = refresh_session()
            time.sleep(2)

        for item in items:
            try:
                title = item.select_one("h3.title .ellipsis-target").text.strip()
                link = "https://www.fmkorea.com" + item.select_one("a.hotdeal_var8")["href"]

                # ì´ë¯¸ì§€ URLì—ì„œ ê²Œì‹œ ì‹œê°„ ì¶”ì¶œ
                image_tag = item.select_one("img.thumb")
                image_url = image_tag.get("data-original") or image_tag.get("src")

                if image_url and "?c=" in image_url:
                    timestamp_raw = image_url.split("?c=")[-1]
                    posted_at = datetime.strptime(timestamp_raw, "%Y%m%d%H%M%S")
                else:
                    posted_at = None

                # ê²Œì‹œ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë‹¨ ì—¬ë¶€ íŒë‹¨
                if posted_at and (now - posted_at > timedelta(days=max_days)):
                    print(f"â¹ï¸ ì¤‘ë‹¨: {posted_at} â†’ 7ì¼ ì´ˆê³¼")
                    stop = True
                    break

                # ê¸°íƒ€ ì •ë³´ ì¶”ì¶œ
                price = item.select_one(".hotdeal_info span:nth-of-type(2) a").text.strip()
                site = item.select_one(".hotdeal_info span:nth-of-type(1) a").text.strip()
                delivery = item.select_one(".hotdeal_info span:nth-of-type(3) a").text.strip()
                comments = item.select_one(".comment_count").text.strip("[]")
                recommend = item.select_one(".pc_voted_count .count").text.strip()
                author = item.select_one(".author").text.strip(" /")
                category = item.select_one(".category a").text.strip()

                # ì¶œë ¥
                print(f"ğŸ›’ ì œëª©: {title}")
                print(f"ğŸ”— ë§í¬: {link}")
                print(f"ğŸ•’ ê²Œì‹œì‹œê°„: {posted_at}")
                print(f"ğŸ’¬ ëŒ“ê¸€: {comments} / ì¶”ì²œ: {recommend}")
                print(f"ğŸ·ï¸ ì‡¼í•‘ëª°: {site} / ê°€ê²©: {price} / ë°°ì†¡: {delivery}")
                print(f"ğŸ“‚ ì¹´í…Œê³ ë¦¬: {category} / ì‘ì„±ì: {author}")
                print("-" * 60)

            except Exception as e:
                print("âŒ ì˜¤ë¥˜ ë°œìƒ:", e)

        # ëœë¤ ë”œë ˆì´ (0.5ì´ˆ ~ 2ì´ˆ)
        time.sleep(random.uniform(0.5, 1.0))
        page += 1

    except Exception as e:
        print(f"âŒ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}")
        break
